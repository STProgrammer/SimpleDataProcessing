{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03022c86",
   "metadata": {},
   "source": [
    "# Data Cleaning + 5-Chart EDA (Template)\n",
    "\n",
    "**Purpose:** Fast, standardized delivery for Fiverr clients.  \n",
    "**Inputs:** A CSV/XLSX file path.  \n",
    "**Outputs:** Cleaned dataset, 5 charts (PNGs), and a short insights summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bed1001-486e-41f9-8d96-17a23453e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== SaaS Churn Portfolio Notebook/Script =====================\n",
    "# Raw columns expected (case-sensitive):\n",
    "# user_id, signup_date, plan, country, monthly_churn_prob, churn_month, arpu, churned\n",
    "#\n",
    "# Outputs:\n",
    "# - saas_clean.csv\n",
    "# - charts/*.png (10 plots)\n",
    "#\n",
    "# Libraries: pandas>=2.2, matplotlib>=3.7 (no seaborn)\n",
    "\n",
    "import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ---------- Paths ----------\n",
    "RAW_PATH   = \"saas_raw.csv\"\n",
    "CLEAN_PATH = \"saas_clean.csv\"\n",
    "CHARTS_DIR = \"charts\"\n",
    "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5c81e3-78ab-43aa-ace6-6613c6fb472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset to saas_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- Helpers ----------\n",
    "def _savefig(out_dir: str, filename: str, fig=None, dpi: int = 160):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, filename), dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def _normalize_freq(freq: str) -> str:\n",
    "    \"\"\"Forward-compat mapping for pandas frequency aliases.\"\"\"\n",
    "    mapping = {\n",
    "        \"M\": \"ME\",   # month-end → use MonthEnd\n",
    "        \"Q\": \"QE\",   # quarter-end\n",
    "        \"Y\": \"YE\",   # year-end\n",
    "        \"A\": \"YE\",   # alias for annual end\n",
    "    }\n",
    "    return mapping.get(freq, freq)\n",
    "\n",
    "def _nice_time_axis(ax, idx, freq: str, max_ticks: int = 10, rotate: int = 0):\n",
    "    \"\"\"Clean, compact date ticks by frequency.\"\"\"\n",
    "    n = len(idx)\n",
    "    if n == 0:\n",
    "        return\n",
    "    tick_idx = np.arange(n) if n <= max_ticks else np.linspace(0, n - 1, max_ticks, dtype=int)\n",
    "    ax.set_xticks(idx[tick_idx])\n",
    "\n",
    "    if freq == \"D\":\n",
    "        fmt = mdates.DateFormatter(\"%Y-%m-%d\")\n",
    "    elif freq == \"W\":\n",
    "        fmt = mdates.DateFormatter(\"%Y-W%W\")\n",
    "    elif freq in (\"MS\", \"ME\"):\n",
    "        fmt = mdates.DateFormatter(\"%Y-%m\")\n",
    "    elif freq in (\"QE\", \"QS\"):\n",
    "        # Matplotlib has no %q; synthesize labels if needed\n",
    "        labels = [f\"{d.year}-Q{((d.month-1)//3)+1}\" for d in idx[tick_idx]]\n",
    "        ax.set_xticklabels(labels)\n",
    "        fmt = None\n",
    "    else:\n",
    "        fmt = mdates.AutoDateFormatter(mdates.AutoDateLocator(minticks=4, maxticks=max_ticks))\n",
    "    if fmt is not None:\n",
    "        ax.xaxis.set_major_formatter(fmt)\n",
    "\n",
    "    if rotate:\n",
    "        for t in ax.get_xticklabels():\n",
    "            t.set_rotation(rotate)\n",
    "    ax.figure.autofmt_xdate()\n",
    "    ax.margins(x=0.01)\n",
    "\n",
    "def _has(df, cols):\n",
    "    return all(c in df.columns for c in cols)\n",
    "\n",
    "# ---------- Load ----------\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "# ---------- Cleaning (safe & minimal) ----------\n",
    "# 1) Trim strings early\n",
    "for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# 2) Parse signup_date safely\n",
    "if \"signup_date\" in df.columns:\n",
    "    df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], errors=\"coerce\")\n",
    "\n",
    "# 3) Canonicalize categoricals\n",
    "for c in [\"plan\", \"country\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip().str.title()\n",
    "\n",
    "# 4) Numeric coercions (no deprecated options used)\n",
    "for c in [\"monthly_churn_prob\", \"churn_month\", \"arpu\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# 5) Derive churned from churn_month (raw has no churned)\n",
    "#    Rule: churned = 1 if churn_month > 0, else 0. If churn_month missing → leave churned as NaN.\n",
    "if \"churn_month\" in df.columns:\n",
    "    cm = pd.to_numeric(df[\"churn_month\"], errors=\"coerce\")\n",
    "    df[\"churned\"] = (cm.fillna(0) > 0).astype(int)\n",
    "else:\n",
    "    # churn_month not present — keep churned absent to avoid wrong inference\n",
    "    if \"churned\" in df.columns:\n",
    "        del df[\"churned\"]\n",
    "\n",
    "# 6) Final typing / validations\n",
    "if \"churn_month\" in df.columns:\n",
    "    # ensure integer >= 0\n",
    "    df[\"churn_month\"] = cm.fillna(0).clip(lower=0).round().astype(int)\n",
    "\n",
    "if \"monthly_churn_prob\" in df.columns:\n",
    "    # keep within [0, 1] if provided as probability; do not scale percentages automatically\n",
    "    df[\"monthly_churn_prob\"] = df[\"monthly_churn_prob\"].clip(lower=0)\n",
    "\n",
    "if \"arpu\" in df.columns:\n",
    "    df[\"arpu\"] = df[\"arpu\"].clip(lower=0)\n",
    "\n",
    "# 7) Drop duplicates; simple numeric impute to stabilize plots\n",
    "df = df.drop_duplicates()\n",
    "for c in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# ---------- Save cleaned ----------\n",
    "df.to_csv(CLEAN_PATH, index=False)\n",
    "print(f\"Saved cleaned dataset to {CLEAN_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9393204-99fc-4f2a-bd66-495c0d6e78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Callable Plot Functions (10) =====================\n",
    "\n",
    "# 1) Signups per period (bar)\n",
    "def plot_signups_by_period(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str = \"signup_date\",\n",
    "    freq: str = \"W\",                 # \"D\",\"W\",\"MS\",\"ME\"\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"1_signups_by_week.png\",\n",
    "    rotate_xticks: int = 45,\n",
    "    max_ticks: int = 10\n",
    "):\n",
    "    if not _has(df, [date_col]):\n",
    "        return\n",
    "    freq = _normalize_freq(freq)\n",
    "    dates = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    ok = dates.notna()\n",
    "    ts = (pd.DataFrame({date_col: dates[ok]})\n",
    "          .set_index(date_col).resample(freq).size())\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 6 if freq == \"W\" else 20 if freq in (\"MS\",\"ME\") else 0.9\n",
    "    ax.bar(ts.index, ts.values, width=width)\n",
    "    label = \"Day\" if freq==\"D\" else \"Week\" if freq==\"W\" else \"Month\"\n",
    "    ax.set_title(f\"New Signups per {label}\"); ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Signups\")\n",
    "    _nice_time_axis(ax, ts.index, freq=freq, max_ticks=max_ticks, rotate=rotate_xticks)\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 2) Plan mix (bar)\n",
    "def plot_plan_mix(\n",
    "    df: pd.DataFrame,\n",
    "    plan_col: str = \"plan\",\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"2_plan_mix.png\"\n",
    "):\n",
    "    if not _has(df, [plan_col]):\n",
    "        return\n",
    "    s = df[plan_col].value_counts()\n",
    "    fig, ax = plt.subplots()\n",
    "    s.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Plan Mix\"); ax.set_xlabel(\"Plan\"); ax.set_ylabel(\"Users\")\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 3) Churn rate by plan (bar) — robust\n",
    "def plot_churn_rate_by_plan(\n",
    "    df: pd.DataFrame,\n",
    "    plan_col: str = \"plan\",\n",
    "    churned_col: str = \"churned\",\n",
    "    out_dir: str = \"charts\",\n",
    "    outfile: str = \"3_churn_rate_by_plan.png\",\n",
    "    min_signups: int = 1  # set >1 to hide tiny cohorts\n",
    "):\n",
    "    if plan_col not in df.columns or churned_col not in df.columns:\n",
    "        return False\n",
    "\n",
    "    # Clean/standardize\n",
    "    plans = df[plan_col].astype(str).str.strip()\n",
    "    churned = pd.to_numeric(df[churned_col], errors=\"coerce\")\n",
    "\n",
    "    # Force binary {0,1}\n",
    "    churned = churned.fillna(0).clip(0, 1).round().astype(int)\n",
    "\n",
    "    mask = plans.notna()\n",
    "    g = pd.DataFrame({plan_col: plans[mask], churned_col: churned[mask]})\n",
    "    if g.empty: \n",
    "        return False\n",
    "\n",
    "    agg = g.groupby(plan_col, dropna=True).agg(\n",
    "        churn_rate=(churned_col, \"mean\"),\n",
    "        signups=(churned_col, \"size\")\n",
    "    )\n",
    "    agg = agg[agg[\"signups\"] >= min_signups].sort_values(\"churn_rate\", ascending=False)\n",
    "    if agg.empty:\n",
    "        return False\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    agg[\"churn_rate\"].plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Churn Rate by Plan\")\n",
    "    ax.set_xlabel(\"Plan\"); ax.set_ylabel(\"Churn Rate\")\n",
    "    # annotate counts\n",
    "    for i, (idx, row) in enumerate(agg.iterrows()):\n",
    "        ax.text(i, row[\"churn_rate\"] + 0.01, f\"n={row['signups']}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "    return True\n",
    "\n",
    "\n",
    "# 4) ARPU by plan (bar)\n",
    "def plot_arpu_by_plan(\n",
    "    df: pd.DataFrame,\n",
    "    plan_col: str = \"plan\",\n",
    "    arpu_col: str = \"arpu\",\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"4_arpu_by_plan.png\"\n",
    "):\n",
    "    if not _has(df, [plan_col, arpu_col]):\n",
    "        return\n",
    "    s = df.groupby(plan_col)[arpu_col].mean()\n",
    "    fig, ax = plt.subplots()\n",
    "    s.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"ARPU by Plan\"); ax.set_xlabel(\"Plan\"); ax.set_ylabel(\"ARPU ($)\")\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 5) Retention curves by plan (months since signup; theoretical from churn prob or empirical from churn_month)\n",
    "def plot_retention_curves(\n",
    "    df: pd.DataFrame,\n",
    "    plan_col: str = \"plan\",\n",
    "    churn_prob_col: str = \"monthly_churn_prob\",\n",
    "    churn_month_col: str = \"churn_month\",\n",
    "    months: int = 12,\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"5_retention_curves.png\"\n",
    "):\n",
    "    if not _has(df, [plan_col]):\n",
    "        return\n",
    "    fig, ax = plt.subplots()\n",
    "    plotted = False\n",
    "\n",
    "    # Prefer empirical survival if churn_month present\n",
    "    if churn_month_col in df.columns:\n",
    "        for plan, g in df.groupby(plan_col):\n",
    "            cm = g[churn_month_col].fillna(0).clip(lower=0).astype(int).to_numpy()\n",
    "            surv = []\n",
    "            for m in range(0, months+1):\n",
    "                # survived beyond m if churn_month==0 (not churned in window) or > m\n",
    "                survived = ((cm == 0) | (cm > m)).mean()\n",
    "                surv.append(survived)\n",
    "            ax.plot(range(0, months+1), surv, label=str(plan))\n",
    "            plotted = True\n",
    "\n",
    "    # Fallback: theoretical geometric survival from monthly churn prob\n",
    "    elif churn_prob_col in df.columns:\n",
    "        for plan, g in df.groupby(plan_col):\n",
    "            p = g[churn_prob_col].dropna().median()\n",
    "            surv = [(1 - p) ** m for m in range(0, months+1)]\n",
    "            ax.plot(range(0, months+1), surv, label=str(plan))\n",
    "            plotted = True\n",
    "\n",
    "    if not plotted:\n",
    "        plt.close(fig); return\n",
    "\n",
    "    ax.set_title(\"Retention Curves by Plan (0–12 months)\")\n",
    "    ax.set_xlabel(\"Months since Signup\"); ax.set_ylabel(\"Retention\")\n",
    "    ax.legend()\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 6) MRR timeline (month-end) — sum ARPU across active users per calendar month\n",
    "def plot_mrr_timeline(\n",
    "    df: pd.DataFrame,\n",
    "    user_col: str = \"user_id\",\n",
    "    signup_col: str = \"signup_date\",\n",
    "    churn_month_col: str = \"churn_month\",\n",
    "    arpu_col: str = \"arpu\",\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"6_mrr_timeline.png\",\n",
    "    freq: str = \"ME\",\n",
    "    rotate_xticks: int = 45,\n",
    "    max_ticks: int = 12\n",
    "):\n",
    "    if not _has(df, [user_col, signup_col, arpu_col]):\n",
    "        return\n",
    "    freq = _normalize_freq(freq)\n",
    "\n",
    "    # bounds\n",
    "    sdates = pd.to_datetime(df[signup_col], errors=\"coerce\")\n",
    "    ok = sdates.notna() & df[arpu_col].notna()\n",
    "    if ok.sum() == 0: return\n",
    "    min_month = sdates[ok].min().to_period(\"M\").to_timestamp(how=\"end\")\n",
    "    max_month = sdates[ok].max().to_period(\"M\").to_timestamp(how=\"end\")\n",
    "    # extend horizon by 12 months or observed churn horizon\n",
    "    horizon = 12\n",
    "    if churn_month_col in df.columns and df[churn_month_col].notna().any():\n",
    "        horizon = max(horizon, int(df[churn_month_col].max()))\n",
    "    max_month = max_month + pd.offsets.MonthEnd(horizon)\n",
    "\n",
    "    idx = pd.date_range(min_month, max_month, freq=\"ME\")\n",
    "    mrr = pd.Series(0.0, index=idx)\n",
    "\n",
    "    # accumulate ARPU for each active month per user\n",
    "    for _, row in df[ok].iterrows():\n",
    "        start = pd.Timestamp(row[signup_col]).to_period(\"M\").to_timestamp(how=\"end\")\n",
    "        months_active = int(row[churn_month_col]) if churn_month_col in df.columns and pd.notna(row[churn_month_col]) and row[churn_month_col] > 0 else horizon\n",
    "        end = start + pd.offsets.MonthEnd(months_active)\n",
    "        rng = pd.date_range(start, min(end, idx[-1]), freq=\"ME\")\n",
    "        mrr[rng] = mrr[rng] + float(row[arpu_col])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(mrr.index, mrr.values)\n",
    "    ax.set_title(\"MRR Timeline\"); ax.set_xlabel(\"Month\"); ax.set_ylabel(\"MRR ($)\")\n",
    "    _nice_time_axis(ax, mrr.index, freq=freq, max_ticks=max_ticks, rotate=rotate_xticks)\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 7) Churn rate by country (bar) — robust\n",
    "def plot_country_churn_rate(\n",
    "    df: pd.DataFrame,\n",
    "    country_col: str = \"country\",\n",
    "    churned_col: str = \"churned\",\n",
    "    out_dir: str = \"charts\",\n",
    "    outfile: str = \"7_country_churn_rate.png\",\n",
    "    top_n: int = 10,\n",
    "    min_signups: int = 1\n",
    "):\n",
    "    if country_col not in df.columns or churned_col not in df.columns:\n",
    "        return False\n",
    "\n",
    "    countries = df[country_col].astype(str).str.strip().str.title()\n",
    "    churned = pd.to_numeric(df[churned_col], errors=\"coerce\").fillna(0).clip(0, 1).round().astype(int)\n",
    "\n",
    "    g = pd.DataFrame({country_col: countries, churned_col: churned})\n",
    "    g = g[g[country_col].notna()]\n",
    "    if g.empty:\n",
    "        return False\n",
    "\n",
    "    agg = g.groupby(country_col, dropna=True).agg(\n",
    "        churn_rate=(churned_col, \"mean\"),\n",
    "        signups=(churned_col, \"size\")\n",
    "    )\n",
    "    agg = agg[agg[\"signups\"] >= min_signups]\n",
    "    if agg.empty:\n",
    "        return False\n",
    "\n",
    "    # show top_n by churn_rate\n",
    "    agg = agg.sort_values([\"churn_rate\", \"signups\"], ascending=[False, False]).head(top_n)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    agg[\"churn_rate\"].plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Churn Rate by Country (Top)\")\n",
    "    ax.set_xlabel(\"Country\"); ax.set_ylabel(\"Churn Rate\")\n",
    "    for i, (idx, row) in enumerate(agg.iterrows()):\n",
    "        ax.text(i, row[\"churn_rate\"] + 0.01, f\"n={row['signups']}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "    return True\n",
    "\n",
    "\n",
    "# 8) ARPU distribution (hist)\n",
    "def plot_arpu_hist(\n",
    "    df: pd.DataFrame,\n",
    "    arpu_col: str = \"arpu\",\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"8_arpu_hist.png\",\n",
    "    bins: int = 40\n",
    "):\n",
    "    if not _has(df, [arpu_col]): return\n",
    "    x = pd.to_numeric(df[arpu_col], errors=\"coerce\").dropna()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(x, bins=bins)\n",
    "    ax.set_title(\"ARPU Distribution\"); ax.set_xlabel(\"ARPU ($)\"); ax.set_ylabel(\"Users\")\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "\n",
    "# 9) Tenure (months until churn) histogram — churned users only\n",
    "def plot_tenure_hist(\n",
    "    df: pd.DataFrame,\n",
    "    churn_month_col: str = \"churn_month\",\n",
    "    churned_col: str = \"churned\",\n",
    "    out_dir: str = \"charts\",\n",
    "    outfile: str = \"9_tenure_hist.png\",\n",
    "    max_bins: int = 12\n",
    "):\n",
    "    if churn_month_col not in df.columns or churned_col not in df.columns:\n",
    "        return False\n",
    "\n",
    "    churned = pd.to_numeric(df[churned_col], errors=\"coerce\").fillna(0).clip(0, 1).round().astype(int)\n",
    "    tenure = pd.to_numeric(df[churn_month_col], errors=\"coerce\")\n",
    "\n",
    "    # keep churned users with positive tenure\n",
    "    x = tenure[(churned == 1) & (tenure.notna()) & (tenure > 0)].astype(int)\n",
    "    if x.empty:\n",
    "        return False\n",
    "\n",
    "    # Nice integer bins from 1..max observed (cap to max_bins if huge)\n",
    "    m = int(x.max())\n",
    "    if m <= max_bins:\n",
    "        bins = range(1, m + 2)  # inclusive last bin\n",
    "    else:\n",
    "        bins = max_bins\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.hist(x, bins=bins, align=\"left\", rwidth=0.9)\n",
    "    ax.set_title(\"Tenure Until Churn (Months) — Churned Users\")\n",
    "    ax.set_xlabel(\"Months\"); ax.set_ylabel(\"Users\")\n",
    "    _savefig(out_dir, outfile, fig)\n",
    "    return True\n",
    "\n",
    "\n",
    "# 10) LTV by plan (naive) = ARPU / median(monthly_churn_prob)\n",
    "def plot_ltv_by_plan(\n",
    "    df: pd.DataFrame,\n",
    "    plan_col: str = \"plan\",\n",
    "    arpu_col: str = \"arpu\",\n",
    "    churn_prob_col: str = \"monthly_churn_prob\",\n",
    "    out_dir: str = CHARTS_DIR,\n",
    "    outfile: str = \"10_ltv_by_plan.png\"\n",
    "):\n",
    "    if not _has(df, [plan_col, arpu_col, churn_prob_col]): return\n",
    "    agg = df.groupby(plan_col).agg(\n",
    "        arpu=(\"arpu\", \"median\"),\n",
    "        p=(\"monthly_churn_prob\", \"median\")\n",
    "    ).replace({0: np.nan})\n",
    "    agg = agg.dropna()\n",
    "    if agg.empty: return\n",
    "    agg[\"ltv\"] = agg[\"arpu\"] / agg[\"p\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    agg[\"ltv\"].plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Naive LTV by Plan (ARPU / churn_prob)\"); ax.set_xlabel(\"Plan\"); ax.set_ylabel(\"LTV ($)\")\n",
    "    _savefig(out_dir, outfile, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bf876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Run All (with column guards, SaaS churn) =====================\n",
    "\n",
    "def _has(df, cols):\n",
    "    return all(c in df.columns for c in cols)\n",
    "\n",
    "# 1) Signups per period (weekly)\n",
    "if _has(df, [\"signup_date\"]):\n",
    "    plot_signups_by_period(\n",
    "        df, freq=\"W\", outfile=\"1_signups_by_week.png\", rotate_xticks=45, max_ticks=10\n",
    "    )\n",
    "\n",
    "# 2) Plan mix\n",
    "if _has(df, [\"plan\"]):\n",
    "    plot_plan_mix(\n",
    "        df, outfile=\"2_plan_mix.png\"\n",
    "    )\n",
    "\n",
    "# 3) Churn rate by plan (requires: plan, churned)\n",
    "if _has(df, [\"plan\", \"churned\"]):\n",
    "    plot_churn_rate_by_plan(\n",
    "        df, outfile=\"3_churn_rate_by_plan.png\", min_signups=1\n",
    "    )\n",
    "\n",
    "# 4) ARPU by plan (requires: plan, arpu)\n",
    "if _has(df, [\"plan\", \"arpu\"]):\n",
    "    plot_arpu_by_plan(\n",
    "        df, outfile=\"4_arpu_by_plan.png\"\n",
    "    )\n",
    "\n",
    "# 5) Retention curves — prefer empirical (plan + churn_month), else theoretical (plan + monthly_churn_prob)\n",
    "if _has(df, [\"plan\", \"churn_month\"]) or _has(df, [\"plan\", \"monthly_churn_prob\"]):\n",
    "    plot_retention_curves(\n",
    "        df, months=12, outfile=\"5_retention_curves.png\"\n",
    "    )\n",
    "\n",
    "# 6) MRR timeline (requires: user_id, signup_date, arpu)\n",
    "if _has(df, [\"user_id\", \"signup_date\", \"arpu\"]):\n",
    "    plot_mrr_timeline(\n",
    "        df, outfile=\"6_mrr_timeline.png\", freq=\"ME\", rotate_xticks=45, max_ticks=12\n",
    "    )\n",
    "\n",
    "# 7) Country churn rate (requires: country, churned)\n",
    "if _has(df, [\"country\", \"churned\"]):\n",
    "    plot_country_churn_rate(\n",
    "        df, outfile=\"7_country_churn_rate.png\", top_n=10, min_signups=1\n",
    "    )\n",
    "\n",
    "# 8) ARPU histogram (requires: arpu)\n",
    "if _has(df, [\"arpu\"]):\n",
    "    plot_arpu_hist(\n",
    "        df, outfile=\"8_arpu_hist.png\", bins=40\n",
    "    )\n",
    "\n",
    "# 9) Tenure histogram (requires: churn_month, churned)\n",
    "if _has(df, [\"churn_month\", \"churned\"]):\n",
    "    plot_tenure_hist(\n",
    "        df, outfile=\"9_tenure_hist.png\", max_bins=12\n",
    "    )\n",
    "\n",
    "# 10) Naive LTV by plan (requires: plan, arpu, monthly_churn_prob)\n",
    "if _has(df, [\"plan\", \"arpu\", \"monthly_churn_prob\"]):\n",
    "    plot_ltv_by_plan(\n",
    "        df, outfile=\"10_ltv_by_plan.png\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cfe65",
   "metadata": {},
   "source": [
    "\n",
    "### Delivery Notes (copy into your PDF summary)\n",
    "- **Data health**: duplicates removed; numeric nulls filled with median (customize as needed).\n",
    "- **Key patterns**: (write 3–5 bullet points referencing the charts)\n",
    "- **Outliers/Warnings**: (mention anomalies, missing ranges, unexpected spikes)\n",
    "- **Next steps**: (what simple analysis/modeling could help their decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc5c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
